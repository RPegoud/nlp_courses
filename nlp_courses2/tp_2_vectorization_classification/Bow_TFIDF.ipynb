{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " this  is  the  first  document  second  and  third  one\n",
      "    1   1    1      1         1       0    0      0    0\n",
      "    1   1    1      0         2       1    0      0    0\n",
      "    1   1    1      0         0       0    1      1    1\n"
     ]
    }
   ],
   "source": [
    "class BoW:\n",
    "    def __init__(self):\n",
    "        self.vocabulary = {} # a dictionary with format {words:word_position}\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "            import pandas as pd\n",
    "            columns = [word for word in self.vocabulary]\n",
    "            df = pd.DataFrame(self.transform(documents), columns=columns)\n",
    "            return df.to_string(index=False)\n",
    "    \n",
    "    def fit(self, documents):\n",
    "        \"\"\"\n",
    "        Fit the BoW model on a list of documents.\n",
    "\n",
    "        Args:\n",
    "        documents (list): A list of text documents.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Your code here: Build the vocabulary from the documents\n",
    "        # iterate through documents, then through words (remember the function we used last course)\n",
    "        # if the word is not part of the vocabulary, add it to the dictionary and update the vocabulary size\n",
    "        # do not return anything\n",
    "        for doc in documents:\n",
    "            filtered_words = [word for word in doc.split() if word.isalnum()]\n",
    "            for word in filtered_words:\n",
    "                if word not in self.vocabulary:\n",
    "                    self.vocabulary[word] = self.vocab_size\n",
    "                    self.vocab_size += 1\n",
    "         \n",
    "            \n",
    "\n",
    "    def transform(self, documents):\n",
    "        \"\"\"\n",
    "        Transform a list of documents into BoW representations.\n",
    "\n",
    "        Args:\n",
    "        documents (list): A list of text documents.\n",
    "\n",
    "        Returns:\n",
    "        bow_matrix (list): A list of BoW representations for each document.\n",
    "        \"\"\"\n",
    "        bow_matrix = []\n",
    "\n",
    "        # Your code here: Transform the documents into BoW representations\n",
    "        # for all documents, initialize an array bow_vector of zeros of the size of the vocabulary\n",
    "        # iterate through every word in the document\n",
    "        # if the word is in the vocabulary, increment bow_vector by 1 at the position that matches the word in the vocabulary\n",
    "        # add the vector to bow_matrix\n",
    "        \n",
    "        for doc in documents:\n",
    "            bow_vector = [0] * self.vocab_size\n",
    "            filtered_words = [word for word in doc.split() if word.isalnum()]\n",
    "            for word in filtered_words:\n",
    "                if word in self.vocabulary:\n",
    "                    bow_vector[self.vocabulary[word]] += 1\n",
    "            bow_matrix.append(bow_vector)\n",
    "            \n",
    "\n",
    "        return bow_matrix  \n",
    "\n",
    "# Example usage:\n",
    "documents = [\n",
    "             \"this is the first document\", \n",
    "             \"this document is the second document\", \n",
    "             \"and this is the third one\",\n",
    "             ]\n",
    "\n",
    "bow_model = BoW()\n",
    "bow_model.fit(documents)\n",
    "bow_matrix = bow_model.transform(documents)\n",
    "print(bow_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " this  is  the    first  document   second      and    third      one\n",
      "  0.0 0.0  0.0 0.219722       0.0 0.000000 0.000000 0.000000 0.000000\n",
      "  0.0 0.0  0.0 0.000000       0.0 0.183102 0.000000 0.000000 0.000000\n",
      "  0.0 0.0  0.0 0.000000       0.0 0.000000 0.183102 0.183102 0.183102\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "class TFIDF:\n",
    "    def __init__(self):\n",
    "        # Initialize empty variables to store the vocabulary and document frequency\n",
    "        self.vocabulary = {}\n",
    "        self.doc_freq = {}\n",
    "        self.total_docs = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        # Create a DataFrame to represent the TF-IDF matrix with column names\n",
    "        columns = [word for word in self.vocabulary]\n",
    "        df = pd.DataFrame(self.transform(documents), columns=columns)\n",
    "        return df.to_string(index=False)\n",
    "\n",
    "    def fit(self, documents):\n",
    "        \"\"\"\n",
    "        Fit the TF-IDF model on a list of documents.\n",
    "\n",
    "        Args:\n",
    "        documents (list): A list of text documents.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Step 1: Build the vocabulary and document frequency\n",
    "        # for each document\n",
    "        # get a list of unique words\n",
    "        # iterate through all words, if a word is in the vocabulary, increment its frequency \n",
    "        # otherwise add it to the vocabulary and then increment its frequency\n",
    "        # do not return anything\n",
    "        for doc in documents:\n",
    "            filtered_words = [word for word in doc.split() if word.isalnum()]\n",
    "            for word in filtered_words:\n",
    "                if word in self.vocabulary:\n",
    "                    self.doc_freq[word] += 1\n",
    "                else:\n",
    "                    self.vocabulary[word] = len(self.vocabulary)\n",
    "                    self.doc_freq[word] = 1\n",
    "            self.total_docs += 1\n",
    "\n",
    "\n",
    "    def transform(self, documents):\n",
    "        \"\"\"\n",
    "        Transform a list of documents into TF-IDF representations.\n",
    "\n",
    "        Args:\n",
    "        documents (list): A list of text documents.\n",
    "\n",
    "        Returns:\n",
    "        tfidf_matrix (list): A list of TF-IDF representations for each document.\n",
    "        \"\"\"\n",
    "        # Step 2: Initialize an empty list for tfidf_matrix\n",
    "        tfidf_matrix = []\n",
    "\n",
    "        # Your code here: Transform the documents into TF-IDF representations\n",
    "        # for all docs\n",
    "        # initialize the tfidf vector\n",
    "        # create an empty word frequency dictionary\n",
    "        # fill the tfidf vector, similar to bag of words\n",
    "            # for all words and frequencies \n",
    "            # compute the tf and idf values and multiply them\n",
    "            # append the tfidf vector to the matrix\n",
    "\n",
    "        tfidf_matrix = []\n",
    "\n",
    "        # Create a vocabulary list from the vocabulary dictionary\n",
    "        vocabulary_list = list(self.vocabulary.keys())\n",
    "\n",
    "        for doc in documents:\n",
    "            tfidf_vector = [0] * len(self.vocabulary)\n",
    "            word_freq = {}\n",
    "            filtered_words = [word for word in doc.split() if word.isalnum()]\n",
    "            for word in filtered_words:\n",
    "                if word in word_freq:\n",
    "                    word_freq[word] += 1\n",
    "                else:\n",
    "                    word_freq[word] = 1\n",
    "            for word, freq in word_freq.items():\n",
    "                if word in self.vocabulary:\n",
    "                    tf = freq / len(filtered_words)\n",
    "                    idf = math.log(self.total_docs / self.doc_freq[word])\n",
    "                    tfidf_vector[self.vocabulary[word]] = tf * idf\n",
    "            tfidf_matrix.append(tfidf_vector)\n",
    "        return tfidf_matrix\n",
    "\n",
    "# Example usage:\n",
    "documents = [\n",
    "    \"this is the first document\",\n",
    "    \"this document is the second document\",\n",
    "    \"and this is the third one\",\n",
    "]\n",
    "\n",
    "tfidf_model = TFIDF()\n",
    "tfidf_model.fit(documents)\n",
    "tfidf_matrix = tfidf_model.transform(documents)\n",
    "print(tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "262f45c2f7c4647a52b21fdf148897939a0a772c971848ae3fddd645c697c1d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
